# Chapter 14. Consensus

분산 시스템에서 여러 프로세스는 합의 알고리즘을 통해 특정 값에 대해 합의한다.

프로세스들은 참가자 중 한 프로세스가 제안한 어떤 값에 동의해야 하며, 일부 참가 노드에 장애가 발생해도 그래야 한다.

합의 알고리즘의 속성

- Agreement(일치성) : 모든 정상 프로세스는 동일한 값에 대해 합의한다.
- Validity(유효성) : 합의 값은 참가 프로세스 중 한 프로세스가 제안한 값이다.
- Termination(유한성) : 모든 정상 프로세스는 결국 합의에 도달한다.

## Broadcast

한 개의 코디네이터가 모든 노드에 데이터를 전파해 데이터를 복제할 때 주로 브로드캐스트를 사용하지만, 신뢰적인 통신을 보장하는 일은 간단하지 않다.

Best Effort Broadcast : 송신 노드는 모든 대상 노드에 대한 메시지 전달을 보장해야 하며, 노드에 장애가 발생해도 다른 노드가 메시지 전달을 재시도하지 않는다.

신뢰적 브로드캐스트는 장애 감지 알고리즘과 fallback을 사용해 구현할 수 있다.

가장 단순한 fallback : 모든 노드가 전달받은 메시지를 다시 자신이 알고 있는 다른 노드에 전달하는 것 -> 메시지 수가 N^2

## Atomic Broadcast

메시지를 특성 순서대로 전달하기 위해서 신뢰성과 total order를 보장하는 atomic broadcast

다음 두 가지 필수 속성을 보장한다.

- 원자성 : 모든 프로세스가 전달받은 메시지는 일치해야 한다. 모든 정상 프로세스가 메시지를 전달하든지 아무 프로세스도 메시지를 전달하지 않는다.
- 순서 : 모든 정상 프로세스는 메시지를 같은 순서로 전달한다.

### Virtual synchrony

브로드캐스트를 사용해 그룹 간 통신을 지원하는 프레임워크

가상 동기화는 정적 그룹이 아닌 동적 그룹에 메시지를 전달한다.

프로세스를 여러 그룹으로 나누고, 그룹이 존재하는 동안 모든 구성원은 메시지를 동일한 순서로 전달받는다.

순서를 보장하는 일부 브로드캐스트 알고리즘은 시퀀서를 사용해서 메시지를 순서화한다.

이 경우 리더의 상태를 계속 확인해야 하나, 모든 메시지에 대해 프로세스 간 합의하지 않아도 되며 시퀀서 자체의 뷰를 사용하면 되기 때문에 성능 면에서 유리하다.

But : 상용 시스템에서 거의 사용되지 않는다.

### 주키퍼 원자적 브로드캐스트(ZAB)

ZAB의 리더는 임시직이며 알고리즘의 단계를 수행하고 팔로워에 메시지를 브로드캐스트하며 이벤트의 순서를 결정한다.

클라이언트는 새로운 값을 쓰고 최신 값을 읽기 위해서 클러스터 내 하나의 노드와 연결한다. (연결 노드가 리더가 아니라면 리더에 요청을 전달한다)

리더의 고유성을 보장하기 위해 프로토콜의 타임라인을 에포크로 나누고 단조 증가하는 식별 번호를 할당한다.

예비 리더 선출 후 프로토콜 수행 단계

1. Discovery : 각 프로세스가 알고 있는 마지막 에포크를 수집한 다음, 가장 마지막 에포크보다 큰 에포크를 제안한다.
2. Sync : 이전 리더에 발생한 장애 복구, 뒤처진 팔로워를 동기화. 팔로워들에게 리더 선출을 알리고 응답을 기다린다.
3. Broadcast: 모든 팔로워가 동기화 되면 메시지 전파를 다시 시작한다.

모든 팔로워가 현재 에포크의 리더의 제안만 수락한다면 프로토콜의 안정성은 보장된다.

ZAB의 전역적 메시지 순서는 복구 효율을 향상시킨다.

ZAB의 장점은 높은 효율성으로, 브로드캐스트 단계는 단 두 번의 메시지 교환만으로 충분하고, 리더 노드의 장애는 최신 상태의 프로세스가 누락된 메시지를 스트리밍하기만 하면 복구할 수 있다.

## Paxos

Paxos의 참가자는 Proposer, Acceptor, Learner로 구성된다.

- Proposer : 클라이언트로부터 전달받은 값을 제안하고 수락자들의 의견을 수렴한다.
- Acceptor : 제안자가 제안한 값을 수락 또는 거부한다. 내결함성을 위해서는 여러 제안자가 필요하지만, Liveness를 위해서는 Quorum의 동의만 있으면 된다.
- Learner : 수락된 제안의 결과를 각 복제 노드에 저장한다.

참가자는 동시에 여러 역할을 수행할 수 있다.

모든 제안은 클라이언트가 제안한 값과 단조 증가하는 제안 번호로 구성된다.

### Paxos Algorithmn

- Voting :  여러 제안자들은 리더가 되기 위해 서로 경쟁. 제안자 간 경합 시 재시작
- Replication : 제안자는 수락자에게 값을 전파

수락자는 학습자가 가능한 빨리 합의 값을 알 수 있또록 수락하는 즉시 값을 전달한다.

제안자가 한 번에 여러 값을 제안하는 것을 허용하면 알고리즘의 단계를 줄일 수 있다. -> 멀티 팍소스

### 팍소스에서의 쿼럼

쿼럼은 작업을 수행하는 데 필요한 최소 응답 수이며 일반적으로 참가자의 과반수와 같다.

팍소스는 합의의 정의와 모순되는 부정확하거나 일관되지 않은 상태를 만들 수 있는 설정은 없다(안전성 보장)

### 장애 시나리오

둘 이상의 제안자가 경합하는 경우 어느 누구도 과반수를 확보하지 못해 모두 실패하는 상황이 발생할 수 있다.

제안자가 커밋을 시도했지만 수락자가 이미 더 높은 번호의 제안을 수락했을 경우, 여러 제안자가 계속 재시도하고 모두 커밋하지 못하는 상황이 발생할 수 있다.

팍소스 알고리즘은 과반수의 수락자가 정상일 경우에만 장애가 허용된다.

### 멀티 팍소스

복제 단계마다 제안 단계가 선행되어야 하기 때문에 제안 단계를 반복하지 않고 이전 제안자를 그대로 유지하기 위해 특별 제안자라는 리더의 개념을 추가한다.

리더가 존재할 경우 제안 단계를 건너뛰고 값을 전파하고 수락자의 확인을 수집하는 복제 단계를 바로 수행할 수 있다.

리더는 주기적으로 참가자의 상태를 확인하고 정상일 경우 lease를 연장시키며, 참가자는 lease 기간 동안 다른 리더의 제안에는 응답하지 않을 것을 약속한다.

단, lease는 정확성을 보장하는 방법이 아니라 쿼럼 대신 리더를 통해 읽기를 수행할 수 있는 하나의 성능 최적화 기법이다.

상태 스냅숏을 통해 로그의 크기를 관리한다.

### Fast Paxos

모든 제안자가 리더를 통하지 않고 수락자와 직접 통신하면 메시지 교환 횟수가 일반 Paxos보다 1회 줄어든다.

이를 위해 쿼럼 크기를 2f + 1로 늘리고, 총 3f+1의 수락자로 만들면 Fast Paxos이다.

요청이 많을 경우 충돌로 인해 메시지 수와 요청 레이턴시가 증가한다는 것이다.

라운드 단계가 줄었음에도 복제본 수의 증가로 참가자 간 교환되는 메시지가 늘어나 오히려 레이턴시가 더 높을 수 있다.

### 평등주의적 팍소스

특정 작업의 커밋을 담당하는 리더를 선출하고 종속 관계를 조회 및 설정해 순서를 정의할 수 있다. (Egalitarian Paxos, EPaxos)

일반 및 멀티 팍소스의 장점을 모두 가진다.

- 특정 제안의 리더를 선출하는 단계(Pre-accept) : 종속 관게를 확인하고, 순환 종속성 제거 진행
- Pre Accept를 Fast quorum에 전송하고 리더에 전달, 정상이라면 리더는 제안을 커밋

EPaxos에는 두 가지 경로

- Fast path : 종속 관계가 일치할 경우 리더는 패스트 쿼럼에 제안을 커밋
- Slow path : 종속 관계가 일치하지 않을 경우 리더는 각 노드가 종속 관계를 갱신한 뒤에 커밋

### Flexible Paxos

- 모든 수행 단계마다 과반의 서버들과 통신해야 하는가?
- 모든 쿼럼 사이에는 교집합이 존재해야 하는가? 특별 제안자를 선택하는 쿼럼과 값을 수락하는 쿼럼 그리고 모든 수행 인스턴스 사이에는 공통의 노드가 있어야 하는가?

팍소스에서는 리더 선출 쿼럼과 제안 수락의 쿼럼이 겹쳐야 한다.

따라서 쿼럼은 반드시 과반수가 아닌 하나 이상의 노드로 정의할 수 있다.

전체 참가 노드수를 N, 제안 단계에서 필요한 노드 수를 Q1, 수락 단계에서 필요한 노드 수를 Q2라고 했을 때, Q1 + Q2 > N이 만족되어야 하며, 이 과정에서 Q1을 알맞게 늘릴 수 있다. -> Flexible Paxos

### 합의를 도출하는 일반적인 방법들

참가자 사이에 역할을 분담하고 의사 결정 단계를 수행하는 대신 더 단순한 개념과 규칙으로 단일 결정형 팍소스를 구현할 수 있다.

(책 p368에 여러 규칙)

여러 규칙들을 합치면 한 번만 쓰기 레지스터를 사용해 특정 값에 대해 합의를 이룰 수 있는 Generalized Paxos 알고리즘을 구현할 수 있다.

## Raft

**분산 시스템은 본질적으로 복잡하기 때문에 알고리즘도 단순할수록 좋다**

- 후보자 : 리더 역할은 일시적으로 유지되며 어떤 노드라도 리더가 될 수 있다. 리더가 되기 위해 노드는 후보자 상태가 되고 과반의 표를 얻어야 한다.
- 리더 : 클라이언트 요청을 처리하고 복제된 상태 기계와 상호작용한다. 임기는 순차 증가하는 숫자이며 여러 장애 발생시 새로운 리더를 선출한다.
- 팔로워 : 로그를 저장하고 리더와 후보자의 요청에 응답하는 수동적인 참가자로, 팍소스의 수락자와 학습자의 역할과 유사하다.

클럭 동기화를 사용하지 않고 전역 부분 순서를 보장하기 위해 Epoch 단위로 시간을 나눈다.

- 리더 선출
- 주기적 하트비트 : 리더는 역할 유지를 위해 주기적으로 모든 팔로워에 하트비트를 전송한다. 타임아웃을 통해 리더 장애를 판단한다.
- 로그 복제/브로드캐스트

### Raft's leader

모든 커밋된 항목이 저장된 노드만이 리더가 될 수 있다. 팔로워의 로그가 후보자보다 최신이라면 팔로워는 투표를 거부한다.

과반 복제가 완료되면 리더는 로컬에 값을 커밋하고 커밋 결정을 팔로워에 복제한다.

### 장애 시나리오

 Split vote : 후보자들 선출이 반복될 수 있음. -> Raft는 무작위 타이머를 통해 투표 분산이 일어날 확률을 낮춤

 팔로워는 시퀀스 ID를 통해 중복을 제거하고, 로그의 순서를 보장하는 데에도 시퀀스 ID를 사용.

래프트의 속성

- 임기 동안 하나의 리더만 선출될 수 있다. 같은 임기 동안 여러 리더가 동시에 존재할 수 없다.
- 리더는 자신의 로그 항목을 삭제하거나 재배치하지 않고 새로운 메시지를 append only
- 리더는 모든 로그 항목을 커밋하기 전에 우선 복제하기 때문에 커밋된 항목은 모든 리더가 공통적으로 저장하며 이를 되돌릴 수 없다.
- 로그 항목은 커밋 전에 먼저 복제 되기 때문에 모든 차기 리더의 로그에 존재한다.
- 메시지는 메시지 번호와 임기 ID로 식별된다. 식별자는 다른 항목에 재사용될 수 없다.

## 비잔틴 합의 

상기 합의 알고리즘은 Byzantine 장애를 허용하지 않는다. (알고리즘을 수행하는 노드가 알고리즘을 악용하거나 결과 위조를 시도하지 않는 선의의 참가자라고 가정)

비잔틴 장애는 악의적 의도 외에도 버그, 설정 오류, 하드웨어 문제 또는 데이터 손상으로 인해 발생할 수 있다.

### PBFT 알고리즘

f개의 노드에 장애가 발생할 수 있다면, 시스템에는 최소 n = 3f + 1개 노드가 있어야 한다.

장애가 발생하더라도 모든 정상 복제 노드는 제안 값과 순서에 대해 동의해야 한다.

PBFT는 View 단위로 클러스터를 구분하며, 각 뷰는 하나의 primary 노드와 여러 백업 노드로 구성된다.

### 복구와 체크포인트

노드들은 다이제스트를 비교해 상태의 무결성을 검증하고, 복구 시 전달받은 메시지가 유효한 최신 상태인지 확인하지만.. 모든 요청마다 수행하기에는 비용이 높다.

기본 노드는 N개의 요청마다 체크포인트를 저장한다.

비잔틴 장애를 허용하는 알고리즘은 메시지 수 측면에서 상당한 오버헤드가 발생하지만, 대립적 네트워크 환경을 허용하는 여러 스토리지 시스템에 사용된다.
